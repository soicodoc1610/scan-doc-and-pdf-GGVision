{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chuy·ªÉn t·∫•t c·∫£ file PDF sang folder ri√™ng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import io\n",
    "import time\n",
    "import fitz  # PyMuPDF ƒë·ªÉ ƒë·∫øm s·ªë trang ch√≠nh x√°c\n",
    "from google.cloud import vision\n",
    "from pdf2image import convert_from_path\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ ƒê·∫∑t ƒë∆∞·ªùng d·∫´n Google Cloud Vision JSON Key\n",
    "json_key_path = r\"\" #file json c·ªßa m\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = json_key_path  \n",
    "\n",
    "poppler_path = r\"poppler-21.03.0\\Library\\bin\"\n",
    "\n",
    "# ‚úÖ S·ª≠ d·ª•ng ƒëa lu·ªìng ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω\n",
    "workers = 30 #CPU 12600KF 10 nh√¢n 16 lu·ªìng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ C·∫•u h√¨nh th∆∞ m·ª•c tr√™n m√°y t√≠nh\n",
    "data_folder = r\"Data\"\n",
    "input_folder = os.path.join(data_folder, \"Input\")  # Th∆∞ m·ª•c ch·ª©a PDF\n",
    "txt_folder = os.path.join(data_folder, \"Output\", \"Success TXT File\")  # Th∆∞ m·ª•c l∆∞u TXT\n",
    "success_folder = os.path.join(data_folder, \"Output\", \"Success File\") #Th∆∞ m·ª•c l∆∞u PDF convert th√†nh c√¥ng\n",
    "failed_folder = os.path.join(data_folder, \"Output\", \"Failed File\") #Th∆∞ m·ª•c l∆∞u PDF convert th·∫•t b·∫°i\n",
    "downloads_folder = r\"downloads\"  # Th∆∞ m·ª•c g·ªëc ch·ª©a t·∫•t c·∫£ c√°c file pdf ƒë√£ unzip\n",
    "\n",
    "os.makedirs(input_folder, exist_ok=True)\n",
    "os.makedirs(txt_folder, exist_ok=True)\n",
    "os.makedirs(success_folder, exist_ok=True)\n",
    "os.makedirs(failed_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def move_files_recursive(downloads_folder, input_folder):\n",
    "    \"\"\"Duy·ªát to√†n b·ªô th∆∞ m·ª•c con v√† di chuy·ªÉn t·∫•t c·∫£ c√°c file sang input_folder\"\"\"\n",
    "    if not os.path.exists(downloads_folder):\n",
    "        print(f\"‚ùå Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i: {downloads_folder}\")\n",
    "        return\n",
    "\n",
    "    file_count = 0  # ƒê·∫øm s·ªë file ƒë√£ di chuy·ªÉn\n",
    "    for root, _, files in os.walk(downloads_folder):  # Duy·ªát t·∫•t c·∫£ th∆∞ m·ª•c con\n",
    "        for file_name in files:\n",
    "            source_path = os.path.join(root, file_name)\n",
    "            destination_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "            # X·ª≠ l√Ω tr√πng t√™n file (n·∫øu c√≥)\n",
    "            counter = 1\n",
    "            while os.path.exists(destination_path):\n",
    "                file_base, file_ext = os.path.splitext(file_name)\n",
    "                new_name = f\"{file_base}_{counter}{file_ext}\"\n",
    "                destination_path = os.path.join(input_folder, new_name)\n",
    "                counter += 1\n",
    "\n",
    "            try:\n",
    "                shutil.move(source_path, destination_path)\n",
    "                file_count += 1\n",
    "                print(f\"‚úÖ Moved: {file_name} ‚Üí {destination_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå L·ªói khi di chuy·ªÉn {file_name}: {e}\")\n",
    "\n",
    "    print(f\"üéâ T·ªïng s·ªë file ƒë√£ di chuy·ªÉn: {file_count}\")\n",
    "\n",
    "# Ch·∫°y ch∆∞∆°ng tr√¨nh\n",
    "move_files_recursive(downloads_folder, input_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X√≥a c√°c ƒëu√¥i file txt, pdf _1, _2, _3 v√¨ ƒë√≥ l√† file tr√πng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di chuy·ªÉn File t·ª´ Success v√† Failed Folder v·ªÅ Input Folder (Ch·ªâ ch·∫°y code n√†y khi c·∫ßn thi·∫øt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def move_files_back(source_folder, destination_folder):\n",
    "#     for file_name in os.listdir(source_folder):\n",
    "#         source_path = os.path.join(source_folder, file_name)\n",
    "#         destination_path = os.path.join(destination_folder, file_name)\n",
    "#         shutil.move(source_path, destination_path)\n",
    "\n",
    "# # Move files back to input folder\n",
    "# move_files_back(success_folder, input_folder)\n",
    "# move_files_back(failed_folder, input_folder)\n",
    "\n",
    "# print(\"‚úÖ All files moved back to input folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Remove duplicate files across all types\n",
    "deleted_files = []\n",
    "\n",
    "for file in os.listdir(input_folder):\n",
    "    if \"_1.\" in file:  # Check for duplicate pattern (e.g., file_1.pdf, file_1.docx)\n",
    "        original_file = file.replace(\"_1.\", \".\")\n",
    "        original_path = os.path.join(input_folder, original_file)\n",
    "        duplicate_path = os.path.join(input_folder, file)\n",
    "\n",
    "        if os.path.exists(original_path):  # Delete only if original exists\n",
    "            os.remove(duplicate_path)\n",
    "            deleted_files.append(file)\n",
    "\n",
    "# ‚úÖ Display results\n",
    "print(f\"üìÇ T·ªïng s·ªë file ƒë√£ x√≥a: {len(deleted_files)}\")\n",
    "if deleted_files:\n",
    "    print(\"üìå Danh s√°ch file b·ªã x√≥a:\")\n",
    "    for f in deleted_files:\n",
    "        print(f)\n",
    "\n",
    "# ‚úÖ Save log of deleted files\n",
    "deleted_log_path = os.path.join(data_folder, \"deleted_files.txt\")\n",
    "with open(deleted_log_path, \"w\", encoding=\"utf-8\") as log_file:\n",
    "    log_file.write(\"File b·ªã x√≥a:\\n\" + \"\\n\".join(deleted_files) + \"\\n\")\n",
    "\n",
    "print(f\"üìú Danh s√°ch file ƒë√£ x√≥a ƒë∆∞·ª£c l∆∞u t·∫°i: {deleted_log_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ƒê·∫øm t·ªïng s·ªë file PDF v√† DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_pdf_files = len([f for f in os.listdir(input_folder) if f.lower().endswith(\".pdf\")])\n",
    "print(f\"üìÇ T·ªïng s·ªë file PDF c√≤n: {moved_pdf_files}\")\n",
    "\n",
    "moved_doc_files = len([f for f in os.listdir(input_folder) if f.lower().endswith((\".docx\", \".doc\"))])\n",
    "print(f\"üìÇ T·ªïng s·ªë file DOC/DOCX c√≤n: {moved_doc_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GGVision OCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Kh·ªüi t·∫°o Google Vision Client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# ‚úÖ L·∫•y danh s√°ch t·∫•t c·∫£ file PDF\n",
    "pdf_files = sorted([f for f in os.listdir(input_folder) if f.lower().endswith(\".pdf\")], \n",
    "                   key=lambda f: os.path.getsize(os.path.join(input_folder, f)))\n",
    "total_files = len(pdf_files)\n",
    "\n",
    "# ‚úÖ L·∫•y danh s√°ch file TXT ƒë√£ c√≥ ƒë·ªÉ tr√°nh x·ª≠ l√Ω l·∫°i\n",
    "existing_txt_files = {os.path.splitext(f)[0] for f in os.listdir(txt_folder) if f.endswith(\".txt\")}\n",
    "\n",
    "# ‚úÖ L·ªçc ra danh s√°ch PDF c·∫ßn x·ª≠ l√Ω\n",
    "pdf_files_to_process = [f for f in pdf_files if os.path.splitext(f)[0] not in existing_txt_files]\n",
    "total_files_to_process = len(pdf_files_to_process)\n",
    "\n",
    "print(f\"üìÇ T·ªïng s·ªë file PDF: {total_files}\")\n",
    "print(f\"‚ö° S·ªë file c·∫ßn x·ª≠ l√Ω: {total_files_to_process}\")\n",
    "\n",
    "# ‚úÖ Kh√≥a ƒë·ªÉ ƒë·∫£m b·∫£o th·ª© t·ª± in ra ƒë√∫ng\n",
    "print_lock = threading.Lock()\n",
    "\n",
    "# ‚úÖ H√†m OCR tr·ª±c ti·∫øp t·ª´ ·∫£nh trong b·ªô nh·ªõ\n",
    "def extract_text_from_image(image, max_retries=3):\n",
    "    try_count = 0\n",
    "    while try_count < max_retries:\n",
    "        try:\n",
    "            image_byte_array = io.BytesIO()\n",
    "            image.save(image_byte_array, format=\"PNG\")  # Chuy·ªÉn ·∫£nh th√†nh byte\n",
    "            image_byte_array = image_byte_array.getvalue()\n",
    "\n",
    "            vision_image = vision.Image(content=image_byte_array)\n",
    "            response = client.document_text_detection(image=vision_image)\n",
    "\n",
    "            if response.error.message:\n",
    "                raise Exception(response.error.message)\n",
    "\n",
    "            return response.full_text_annotation.text.strip() if response.full_text_annotation.text else \"\"\n",
    "\n",
    "        except Exception as e:\n",
    "            try_count += 1\n",
    "            with print_lock:\n",
    "                print(f\"‚ùå L·ªói OCR ({try_count}/{max_retries}): {str(e)}\")\n",
    "\n",
    "            if \"503\" in str(e):  # L·ªói Google API qu√° t·∫£i\n",
    "                with print_lock:\n",
    "                    print(\"‚è≥ ƒê·ª£i 5 gi√¢y r·ªìi th·ª≠ l·∫°i...\")\n",
    "                time.sleep(5)\n",
    "\n",
    "            elif try_count == max_retries:\n",
    "                with print_lock:\n",
    "                    print(\"‚ùå Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh n√†y sau nhi·ªÅu l·∫ßn th·ª≠!\")\n",
    "                return \"\"\n",
    "\n",
    "# ‚úÖ X·ª≠ l√Ω PDF v·ªõi ƒëa lu·ªìng\n",
    "failed_files = []  # Danh s√°ch file g·∫∑p l·ªói\n",
    "\n",
    "def process_pdf(file_name, index):\n",
    "    pdf_path = os.path.join(input_folder, file_name)\n",
    "    pdf_name = os.path.splitext(file_name)[0]  # L·∫•y t√™n file, b·ªè ƒëu√¥i .pdf\n",
    "    txt_path = os.path.join(txt_folder, f\"{pdf_name}.txt\")\n",
    "\n",
    "    # ‚úÖ Ki·ªÉm tra tr√°nh t·∫°o file tr√πng\n",
    "    if pdf_name in existing_txt_files:\n",
    "        with print_lock:\n",
    "            print(f\"‚ö†Ô∏è B·ªè qua {file_name} (TXT ƒë√£ t·ªìn t·∫°i)\")\n",
    "        return\n",
    "\n",
    "    with print_lock:\n",
    "        print(f\"\\nüìÑ [{index+1}/{total_files_to_process}] ƒêang x·ª≠ l√Ω: {file_name}...\")\n",
    "\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            total_pages = len(doc)\n",
    "        \n",
    "        with print_lock:\n",
    "            print(f\"üìú T·ªïng s·ªë trang: {total_pages}\")\n",
    "\n",
    "        extracted_texts = []\n",
    "        for start_page in range(1, total_pages + 1, 50):\n",
    "            end_page = min(start_page + 49, total_pages)\n",
    "            with print_lock:\n",
    "                print(f\"üîÑ ƒêang x·ª≠ l√Ω t·ª´ trang {start_page} ƒë·∫øn {end_page}...\")\n",
    "\n",
    "            images = convert_from_path(pdf_path, first_page=start_page, last_page=end_page)  \n",
    "\n",
    "            for page_number, image in enumerate(images, start=start_page):\n",
    "                text = extract_text_from_image(image)\n",
    "                time.sleep(1)  # Gi·∫£m t·∫£i API b·∫±ng c√°ch ch·ªù 1 gi√¢y\n",
    "\n",
    "                if text:\n",
    "                    extracted_texts.append(text)\n",
    "\n",
    "        if extracted_texts:\n",
    "            # ‚úÖ X√≥a file TXT n·∫øu ƒë√£ t·ªìn t·∫°i (ƒë·ªÉ tr√°nh t·∫°o file tr√πng)\n",
    "            if os.path.exists(txt_path):\n",
    "                os.remove(txt_path)\n",
    "\n",
    "            # ‚úÖ Ghi ƒë√® file TXT (thay v√¨ append)\n",
    "            with open(txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "                txt_file.write(\"\\n\".join(extracted_texts) + \"\\n\")\n",
    "\n",
    "        shutil.move(pdf_path, os.path.join(success_folder, file_name))\n",
    "    \n",
    "    except Exception as e:\n",
    "        with print_lock:\n",
    "            print(f\"‚ùå L·ªói khi x·ª≠ l√Ω PDF {file_name}: {str(e)}\")\n",
    "        failed_files.append(file_name)\n",
    "        shutil.move(pdf_path, os.path.join(failed_folder, file_name))\n",
    "        return\n",
    "\n",
    "    remaining_files = total_files_to_process - (index + 1)\n",
    "    with print_lock:\n",
    "        print(f\"‚úÖ OCR ho√†n th√†nh: {file_name} -> {txt_path} ({remaining_files} file c√≤n l·∫°i)\")\n",
    "\n",
    "# ‚úÖ Ch·∫°y ƒëa lu·ªìng\n",
    "with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "    executor.map(process_pdf, pdf_files_to_process, range(total_files_to_process))\n",
    "\n",
    "print(\"\\nüéâ Ho√†n th√†nh OCR cho t·∫•t c·∫£ file PDF m·ªõi! üöÄ\")\n",
    "\n",
    "# ‚úÖ Ghi danh s√°ch file l·ªói\n",
    "if failed_files:\n",
    "    failed_files_path = os.path.join(data_folder, \"failed_files.txt\")\n",
    "    with open(failed_files_path, \"w\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(\"\\n\".join(failed_files))\n",
    "    print(f\"‚ö†Ô∏è M·ªôt s·ªë file g·∫∑p l·ªói. Danh s√°ch t·∫°i: {failed_files_path}\")\n",
    "\n",
    "# ‚úÖ Ghi danh s√°ch file ƒë√£ b·ªè qua\n",
    "skipped_files_path = os.path.join(data_folder, \"skipped_files.txt\")\n",
    "with open(skipped_files_path, \"w\", encoding=\"utf-8\") as log_file:\n",
    "    log_file.write(\"\\n\".join(existing_txt_files))\n",
    "print(f\"üìú Danh s√°ch file ƒë√£ b·ªè qua: {skipped_files_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Decor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
